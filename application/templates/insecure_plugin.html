<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Insecure Plugin Design - Pizza Paradise</title>
    <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@300;400;500;700&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta3/css/all.min.css">
    <link rel="stylesheet" href="{{ url_for('static', filename='css/style.css') }}">
</head>
<body>
    <header>
        <div class="container">
            <nav class="navbar">
                <a href="{{ url_for('index') }}" class="logo">Pizza<span>Paradise</span></a>
            </nav>
        </div>
    </header>
    
    {% include 'navbar.html' %}

    <main class="container">
        <h1>Insecure Plugin Design</h1>
        
        <div class="insecure-plugin-content">
            <details class="description-dropdown">
                <summary class="dropdown-title">Description</summary>
                <div class="dropdown-content">
                    <section class="section-box">
                        <p>Insecure plugin vulnerabilities in Large Language Model (LLM) systems represent a growing concern as these models increasingly rely on external tools to extend their capabilities. </p>
                        <p> When a plugin lacks proper input validation or exposes insecure interfaces, it can open up serious attack vectors—such as SQL injection—that may lead to unauthorized database access or manipulation. </p>
                        <p>These vulnerabilities are particularly subtle in the context of LLMs, as the model can act as an interface between user input and the underlying plugin, potentially passing along malicious payloads without detection.</p>
                       
                    </section>
                </div>
            </details>
            
            <details class="description-dropdown" open>
                <summary class="dropdown-title">Demonstration</summary>
                <div class="dropdown-content">
                    <section class="section-box">
                    <p>To illustrate this vulnerability in practice, two demonstrative instances have been developed: one using the open-source LLaMA model hosted on Hugging Face, and the other leveraging the commercial GPT-4o Mini model. </p><p>Both instances are configured to use a plugin that contains a SQL injection flaw, allowing users to observe the potential risks firsthand.</p>
                    <p> These setups require individuals to provide their own API keys, which are securely stored on the client side and never transmitted to external servers. </p>
                
                <!-- Main demo tabs -->
                <div class="model-tabs">
                    <div class="tab-headers">
                        <div class="tab-header active" data-tab="blenderbot-model">HuggingFace Models Implementation</div>
                        <div class="tab-header" data-tab="openai-model">OpenAI Implementation</div>
                    </div>
                    
                    <!-- BlenderBot Tab Content -->
                    <div class="tab-content active" id="blenderbot-model-tab">
                        <div class="model-implementation-section">
                            <!-- Token Input Section -->
                            <div class="token-section">
                                <h3>Connect to Hugging Face API</h3>
                                <p>Enter your Hugging Face API token to enable the pizza assistant chatbot:</p>
                                <div class="token-input">
                                    <input type="password" id="api-token" placeholder="Enter Hugging Face API token...">
                                    <button id="connect-api">Connect API</button>
                                </div>
                                <div id="api-status" class="api-status disconnected">
                                    <i class="fas fa-circle-xmark"></i> Not connected to API
                                </div>
                                <div class="hint-box">
                                    <p><strong>Hint:</strong> For this demo, you can enter any text as the token:</p>
                                    <ul>
                                        <li>This demo uses a mock HuggingFace model running locally</li>
                                        <li>The API token input is kept only to demonstrate the client-side token vulnerability</li>
                                        <li>In a real application, API tokens should never be handled this way</li>
                                    </ul>
                                    <p><strong>SQL Injection Demo:</strong> This implementation is vulnerable to SQL injection attacks. Try prompts like "What's the price of a pizza' UNION SELECT name, content FROM comment --" to see the vulnerability in action.</p>
                                    <p>Normal queries: "How much is a Pepperoni pizza?" or "What's the price of a Margherita?"</p>
                                </div>
                            </div>
                            
                            <!-- Chat Interface -->
                            <h3>Pizza Price Assistant Chat (HuggingFace)</h3>
                            <div class="chat-container">
                                <div id="chat-messages" class="chat-messages">
                                    <div class="message bot-message">
                                        Hi! I'm the Pizza Price Assistant using HuggingFace models. I can help you find prices for our delicious pizzas. Please connect the API first to enable my functionality.
                                    </div>
                                    <div class="message bot-message">
                                        <strong>Try asking:</strong> "What's the price of a Pepperoni pizza?" or "How much is a Margherita?"
                                    </div>
                                </div>
                                <div class="chat-input">
                                    <input type="text" id="user-message" placeholder="Ask about pizza prices..." disabled>
                                    <button id="send-message" disabled>Send</button>
                                </div>
                            </div>
                            
                            <!-- Vulnerability Explanation -->
                            <div class="security-vulnerability">
                                <h3><i class="fas fa-bug"></i> HuggingFace Text-Based Function Execution with SQL Injection</h3>
                                <p>This implementation allows the language model to directly execute SQL injection attacks through text-based function calls:</p>
                                
                                <pre class="code-snippet"># VULNERABLE: SQL injection through HuggingFace model
import sqlite3

def search_pizza_price(pizza_type):
    """
    VULNERABLE: Uses raw SQL queries - susceptible to SQL injection
    """
    conn = None
    try:
        conn = sqlite3.connect('application/instance/pizza_shop.db')
        cursor = conn.cursor()
        
        # VULNERABLE: Direct string concatenation in SQL query
        pizza = pizza_type.lower().replace("pizza", "").strip()
        
        # DANGEROUS: Building SQL query with user input without parameterization
        query = f"SELECT name, price FROM pizza WHERE LOWER(name) LIKE '%{pizza}%'"
        
        cursor.execute(query)
        result = cursor.fetchone()
        
        if result:
            _, price = result
            return f"The {pizza} pizza costs ${price}"
        else:
            return f"Sorry, I couldn't find price information for {pizza} pizza"
            
    except sqlite3.Error as e:
        return f"Database error: {str(e)}"  # Leaks error information
    finally:
        if conn:
            conn.close()

# Mock HuggingFace model that can process SQL injection
class MockHuggingFaceModel:
    def __call__(self, messages):
        user_msg = messages[0]["content"].lower()
        
        # Check for SQL injection patterns and pass them through
        if "union select" in user_msg or "' union" in user_msg:
            if "price" in user_msg and "'" in user_msg:
                # Extract SQL injection payload
                import re
                pattern = r"pizza'[^']*"
                match = re.search(pattern, user_msg)
                if match:
                    payload = match.group(0).replace("pizza'", "").strip()
                    return Response(f"EXECUTE_FUNCTION: search_pizza_price(\"{payload}\")")
        
        # Normal pizza responses
        if "pepperoni" in user_msg:
            return Response("EXECUTE_FUNCTION: search_pizza_price(\"pepperoni\")")

# VULNERABLE: Direct execution without validation
if function_name == "search_pizza_price" and params:
    function_result = search_pizza_price(params)  # SQL injection occurs here
</pre>

                                <div class="vulnerability-explanation">
                                    <h4>Why This Is Critically Insecure - SQL Injection Risk:</h4>
                                    <ul>
                                        <li><strong>SQL Injection:</strong> The HuggingFace model can inject malicious SQL through text-based function calls</li>
                                        <li><strong>Text-Based Function Execution:</strong> The model controls function parameters through generated text</li>
                                        <li><strong>Direct String Concatenation:</strong> SQL queries built with unsafe string concatenation</li>
                                        <li><strong>No Input Validation:</strong> Function parameters from LLM are used directly in SQL queries</li>
                                        <li><strong>Database Error Exposure:</strong> SQL errors are returned to users, leaking system information</li>
                                        <li><strong>Pattern Matching:</strong> Simple regex extraction allows malicious payloads to pass through</li>
                                    </ul>
                                    
                                    <h4>SQL Injection Attack Examples for HuggingFace:</h4>
                                    <p>Try these prompts to demonstrate SQL injection through the HuggingFace model:</p>
                                    <div class="attack-examples">
                                        <p><strong>Basic data extraction:</strong></p>
                                        <code>"What's the price of a pizza' UNION SELECT name, price FROM pizza --"</code>
                                        
                                        <p><strong>Extract customer comments:</strong></p>
                                        <code>"How much is a pizza' UNION SELECT name, content FROM comment --"</code>
                                        
                                        <p><strong>Database schema discovery:</strong></p>
                                        <code>"Price for pizza' UNION SELECT name, sql FROM sqlite_master --"</code>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </div>
                    
                    <!-- OpenAI Tab Content -->
                    <div class="tab-content" id="openai-model-tab">
                        <div class="model-implementation-section">
                            <!-- OpenAI Token Input Section -->
                            <div class="token-section openai-token-section">
                                <h3>Connect to OpenAI API</h3>
                                <p>Enter your OpenAI API key to enable the pizza price assistant:</p>
                                <div class="token-input">
                                    <input type="password" id="openai-api-token" placeholder="Enter OpenAI API key...">
                                    <button id="connect-openai-api">Connect API</button>
                                </div>
                                <div id="openai-api-status" class="api-status disconnected">
                                    <i class="fas fa-circle-xmark"></i> Not connected to OpenAI API
                                </div>
                                <div class="hint-box">
                                    <p><strong>Security Warning:</strong> This demonstrates a highly insecure practice. Never enter actual API keys into untrusted websites.</p>
                                    <p>Your OpenAI API key would be charged for any usage in this demo.</p>
                                    <p><strong>SQL Injection Demo:</strong> This implementation is vulnerable to SQL injection attacks. Try prompts like "What's the price of a pizza' UNION SELECT name, price FROM pizza --" to see the vulnerability in action.</p>
                                </div>
                            </div>
                            
                            <!-- OpenAI Chat Interface -->
                            <h3>Pizza Price Assistant Chat (OpenAI)</h3>
                            <p class="warning-text">⚠️ This demo uses the OpenAI API. You MUST provide a valid OpenAI API key for this to work. Your API key will be sent directly to OpenAI - never do this in a real application!</p>
                            
                            <div class="chat-container">
                                <div id="openai-chat-messages" class="chat-messages">
                                    <div class="message bot-message">
                                        Hi! I'm the Pizza Price Assistant using OpenAI. I can help you find prices for our delicious pizzas. Please connect your OpenAI API key first.
                                    </div>
                                    <div class="message bot-message">
                                        <strong>Try asking:</strong> "What's the price for a Margherita pizza?" or "How much is a Pepperoni pizza?"
                                    </div>
                                </div>
                                <div class="chat-input">
                                    <input type="text" id="openai-user-message" placeholder="Ask about pizza prices..." disabled>
                                    <button id="openai-send-message" disabled>Send</button>
                                </div>
                            </div>
                            
                            <!-- OpenAI Vulnerability Explanation -->
                            <div class="security-vulnerability">
                                <h3><i class="fas fa-bug"></i> OpenAI API Function/Tool Calling with SQL Injection</h3>
                                <p>This implementation uses OpenAI's function calling feature but creates a critical SQL injection vulnerability:</p>
                                
                                <pre class="code-snippet">import json
import sqlite3
from openai import OpenAI

def get_pizza_price(pizza_type):
    """
    VULNERABLE: Get the price for a specific pizza type using raw SQL query
    This function is intentionally vulnerable to SQL injection attacks
    """
    try:
        # Connect to the database
        conn = sqlite3.connect('application/instance/database.db')
        cursor = conn.cursor()
        
        # VULNERABLE: Direct string concatenation in SQL query
        pizza = pizza_type.lower().replace("pizza", "").strip()
        
        # DANGEROUS: Building SQL query with user input without parameterization
        query = f"SELECT name, price FROM pizza WHERE LOWER(name) LIKE '%{pizza}%'"
        
        cursor.execute(query)
        result = cursor.fetchone()
        
        if result:
            name, price = result
            return f"${price}"
        else:
            return "Pizza not found in our menu"
            
    except sqlite3.Error as e:
        return f"Database error: {str(e)}"  # Leaks error information
    finally:
        conn.close()

# Function definition for OpenAI tools
price_function = {
    "name": "get_pizza_price",
    "description": "Get the price for a specific pizza type.",
    "parameters": {
        "type": "object",
        "properties": {
            "pizza_type": {
                "type": "string",
                "description": "The type of pizza you want to know the price for"
            },
        },
        "required": ["pizza_type"],
    },
}

def chat_with_openai(user_input, api_key):
    """
    INSECURE: Use OpenAI API with user-provided API key
    """
    # VULNERABLE: Directly using user-provided API key
    client = OpenAI(api_key=api_key)
    
    # Call OpenAI API with tool/function calling
    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system", "content": "You are a helpful pizza shop assistant."},
            {"role": "user", "content": user_input},
        ],
        tools=[{
            "type": "function",
            "function": price_function
        }],
        tool_choice="auto"  # Let the model decide when to call the function
    )
    
    # Check if the model wants to call the function
    message = response.choices[0].message
    
    if message.tool_calls:
        for tool_call in message.tool_calls:
            if tool_call.function.name == "get_pizza_price":
                # Parse the function arguments
                arguments = json.loads(tool_call.function.arguments)
                pizza_type = arguments.get('pizza_type')
                
                if pizza_type:
                    # VULNERABLE: No validation before executing function
                    price = get_pizza_price(pizza_type)
                    
                    # Get a response that includes the function result
                    second_response = client.chat.completions.create(
                        model="gpt-3.5-turbo",
                        messages=[
                            {"role": "system", "content": "You are a helpful pizza shop assistant."},
                            {"role": "user", "content": user_input},
                            {"role": "assistant", "content": None, "tool_calls": [tool_call]},
                            {"role": "tool", "tool_call_id": tool_call.id, 
                             "content": f"The price for {pizza_type} pizza is {price}"}
                        ],
                    )
                    return second_response.choices[0].message.content
    
    # Return the original response if no function was called
    return message.content
</pre>

                                <div class="vulnerability-explanation">
                                    <h4>Why This Is Critically Insecure - SQL Injection Risk:</h4>
                                    <ul>
                                        <li><strong>SQL Injection:</strong> The LLM can inject malicious SQL code through the pizza_type parameter</li>
                                        <li><strong>Direct String Concatenation:</strong> User input is directly inserted into SQL queries without parameterization</li>
                                        <li><strong>Database Access:</strong> The function has direct database access with no input validation</li>
                                        <li><strong>Error Information Leakage:</strong> Database errors are returned to the user, revealing system information</li>
                                        <li><strong>LLM Control:</strong> The AI model decides what parameters to pass to the vulnerable function</li>
                                        <li><strong>No Input Sanitization:</strong> No filtering or escaping of special SQL characters</li>
                                    </ul>
                                    
                                    <h4>SQL Injection Attack Examples:</h4>
                                    <p>Try these prompts to demonstrate SQL injection through the LLM:</p>
                                    <div class="attack-examples">
                                        <p><strong>Basic injection to see all pizza data:</strong></p>
                                        <code>"What's the price of a pizza' UNION SELECT name, price FROM pizza --"</code>
                                        
                                        <p><strong>Extract database schema information:</strong></p>
                                        <code>"How much is a pizza' UNION SELECT sql, type FROM sqlite_master WHERE type='table' --"</code>
                                        
                                        <p><strong>Extract all comments data:</strong></p>
                                        <code>"Price for pizza' UNION SELECT name, content FROM comment --"</code>
                                        
                                        <p><strong>Count all records in tables:</strong></p>
                                        <code>"What about pizza' UNION SELECT 'Total pizzas:', COUNT(*) FROM pizza --"</code>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
                
                <div class="vulnerability-summary">
                    <h4>Common Security Issues in Both Implementations:</h4>
                    <ul>
                        <li>The LLM has complete control over which functions are called</li>
                        <li>The LLM decides what parameters are passed to the functions</li>
                        <li>A malicious prompt could trick the model into calling dangerous functions</li>
                        <li>There's no validation of function parameters before execution</li>
                        <li>There's no restriction on what functions can be called</li>
                        <li>The system blindly trusts the model's decisions without proper security checks</li>
                    </ul>
                </div>
                
                
                </div>
            </details>
            
            <details class="description-dropdown">
                <summary class="dropdown-title">Mitigation Strategies</summary>
                <div class="dropdown-content">
                    <section class="section-box">
                        <div class="security-tip">
                            <h3><i class="fas fa-shield-alt"></i> Secure Alternative</h3>
                            <p>A secure implementation would address both plugin security and SQL injection:</p>
                            <ul>
                                <li><strong>SQL Injection Prevention:</strong> Use parameterized queries instead of string concatenation</li>
                                <li><strong>Input Validation:</strong> Validate and sanitize all parameters before function execution</li>
                                <li><strong>Limited Database Access:</strong> Use ORM with proper access controls instead of raw SQL</li>
                                <li><strong>Plugin Sandboxing:</strong> Run plugins in isolated environments with restricted permissions</li>
                                <li><strong>Function Allowlisting:</strong> Use a limited set of pre-approved functions only</li>
                                <li><strong>Error Handling:</strong> Never expose database errors or internal system details to users</li>
                            </ul>
                            <p>Example of a secure implementation:</p>
                            <pre class="code-snippet"># SECURE: SQL Injection Prevention & Input Validation
import re
import sqlite3

# Whitelist of allowed pizza names
ALLOWED_PIZZAS = {'margherita', 'pepperoni', 'vegetarian', 'hawaiian', 'bbq chicken'}
SQL_KEYWORDS = ['union', 'select', 'drop', 'delete', 'insert', 'update', 'create', 'alter']

def get_pizza_price_secure(pizza_type):
    """Secure version with comprehensive protections"""
    
    # 1. Input validation
    if not isinstance(pizza_type, str) or len(pizza_type) > 50:
        return "Invalid input"
    
    pizza = pizza_type.lower().replace("pizza", "").strip()
    
    # 2. Block SQL injection keywords
    if any(keyword in pizza.lower() for keyword in SQL_KEYWORDS):
        return "Invalid characters detected"
    
    # 3. Character allowlist (alphanumeric + spaces only)
    if not re.match(r"^[a-zA-Z0-9\s]+$", pizza):
        return "Invalid characters in pizza name"
    
    # 4. Pizza name whitelist
    if not any(allowed in pizza for allowed in ALLOWED_PIZZAS):
        return "Pizza not available"
    
    try:
        conn = sqlite3.connect('application/instance/pizza_shop.db')
        cursor = conn.cursor()
        
        # 5. CRITICAL: Use parameterized query (prevents SQL injection)
        query = "SELECT name, price FROM pizza WHERE LOWER(name) LIKE ? LIMIT 1"
        cursor.execute(query, (f'%{pizza}%',))  # Safe parameter binding
        result = cursor.fetchone()
        
        if result:
            _, price = result
            return f"${price:.2f}"
        else:
            return "Pizza not found"
            
    except sqlite3.Error:
        # 6. Don't expose database errors
        return "Service temporarily unavailable"
    finally:
        if conn:
            conn.close()

# SECURE: Function allowlist with validation
ALLOWED_FUNCTIONS = {
    "get_pizza_price": get_pizza_price_secure
}

def secure_function_executor(function_name, params):
    """Secure function execution with validation"""
    # Only allow whitelisted functions
    if function_name not in ALLOWED_FUNCTIONS:
        return "Function not authorized"
    
    # Additional parameter validation
    if not params or len(params) > 50:
        return "Invalid parameters"
    
    return ALLOWED_FUNCTIONS[function_name](params)
</pre>
                        </div>
                    </section>
                </div>
            </details>
        </div>
    </main>

    <script>
        document.addEventListener('DOMContentLoaded', function() {
            // Common elements
            const apiTokenInput = document.getElementById('api-token');
            const connectApiButton = document.getElementById('connect-api');
            const apiStatus = document.getElementById('api-status');
            
            // BlenderBot tab elements
            const userMessageInput = document.getElementById('user-message');
            const sendMessageButton = document.getElementById('send-message');
            const chatMessages = document.getElementById('chat-messages');
            
            // OpenAI tab elements
            const openaiApiTokenInput = document.getElementById('openai-api-token');
            const connectOpenaiButton = document.getElementById('connect-openai-api');
            const openaiApiStatus = document.getElementById('openai-api-status');
            const openaiUserMessageInput = document.getElementById('openai-user-message');
            const openaiSendMessageButton = document.getElementById('openai-send-message');
            const openaiChatMessages = document.getElementById('openai-chat-messages');
            
            // INSECURE: Tokens stored in client-side JavaScript AND cookies
            let apiToken = null;
            let openaiApiToken = null;
            
            // Cookie utility functions (INSECURE - storing API keys in cookies)
            function setCookie(name, value, days = 30) {
                const expires = new Date();
                expires.setTime(expires.getTime() + (days * 24 * 60 * 60 * 1000));
                document.cookie = `${name}=${value};expires=${expires.toUTCString()};path=/`;
            }
            
            function getCookie(name) {
                const nameEQ = name + "=";
                const ca = document.cookie.split(';');
                for(let i = 0; i < ca.length; i++) {
                    let c = ca[i];
                    while (c.charAt(0) == ' ') c = c.substring(1, c.length);
                    if (c.indexOf(nameEQ) == 0) return c.substring(nameEQ.length, c.length);
                }
                return null;
            }
            
            // Load API keys from cookies on page load (INSECURE)
            function loadApiKeysFromCookies() {
                const savedHfToken = getCookie('hf_api_token');
                const savedOpenaiToken = getCookie('openai_api_token');
                
                if (savedHfToken) {
                    apiToken = savedHfToken;
                    apiTokenInput.value = '••••••••••••••••'; // Show masked token
                    apiStatus.className = 'api-status connected';
                    apiStatus.innerHTML = '<i class="fas fa-circle-check"></i> Connected to API (from cookie)';
                    userMessageInput.disabled = false;
                    sendMessageButton.disabled = false;
                    console.log("INSECURE: HuggingFace API Token loaded from cookie:", savedHfToken);
                }
                
                if (savedOpenaiToken) {
                    openaiApiToken = savedOpenaiToken;
                    openaiApiTokenInput.value = '••••••••••••••••'; // Show masked token
                    openaiApiStatus.className = 'api-status connected';
                    openaiApiStatus.innerHTML = '<i class="fas fa-circle-check"></i> Connected to OpenAI API (from cookie)';
                    openaiUserMessageInput.disabled = false;
                    openaiSendMessageButton.disabled = false;
                    console.log("INSECURE: OpenAI API Token loaded from cookie:", savedOpenaiToken);
                }
            }
            
            // Tab functionality for all tab groups
            function initializeTabs(headerSelector, contentPrefix) {
                const tabHeaders = document.querySelectorAll(headerSelector);
                
                tabHeaders.forEach(header => {
                    header.addEventListener('click', function() {
                        // Get all headers in this tab group (siblings)
                        const allHeaders = Array.from(this.parentElement.querySelectorAll(headerSelector));
                        
                        // Get all corresponding content tabs
                        const tabContents = allHeaders.map(h => 
                            document.getElementById(h.getAttribute('data-tab') + '-tab')
                        );
                        
                        // Remove active class from all tabs in this group
                        allHeaders.forEach(h => h.classList.remove('active'));
                        tabContents.forEach(c => c?.classList.remove('active'));
                        
                        // Add active class to clicked tab
                        this.classList.add('active');
                        const tabId = this.getAttribute('data-tab') + '-tab';
                        document.getElementById(tabId)?.classList.add('active');
                    });
                });
            }
            
            // Initialize all tab systems
            initializeTabs('.model-tabs .tab-header', '');
            initializeTabs('.chat-tabs .tab-header', '');
            
            // Connect BlenderBot API button
            connectApiButton.addEventListener('click', function() {
                const token = apiTokenInput.value.trim();
                
                if (!token) {
                    alert('Please enter an API token');
                    return;
                }
                
                // INSECURE: Store token in a JavaScript variable AND cookie
                apiToken = token;
                setCookie('hf_api_token', token, 30); // Store for 30 days
                
                // Update UI to show connected state
                apiStatus.className = 'api-status connected';
                apiStatus.innerHTML = '<i class="fas fa-circle-check"></i> Connected to API';
                
                // Enable BlenderBot chat interface
                userMessageInput.disabled = false;
                sendMessageButton.disabled = false;
                
                // Add welcome message
                addBotMessage(chatMessages, "Thanks for connecting! I'm ready to help with pizza information. You can ask questions like 'What's the price of a Pepperoni pizza?' or 'How much does a Margherita cost?'.");
                
                // Show masked token in input
                apiTokenInput.value = '••••••••••••••••';
                
                // VULNERABLE: Log the token to console for demonstration purposes
                console.log("INSECURE: HuggingFace API Token stored in client-side JavaScript AND cookie:", apiToken);
            });
            
            // Connect OpenAI API button
            connectOpenaiButton.addEventListener('click', function() {
                const token = openaiApiTokenInput.value.trim();
                
                if (!token) {
                    alert('Please enter an OpenAI API key');
                    return;
                }
                
                // INSECURE: Store OpenAI token in a JavaScript variable AND cookie
                openaiApiToken = token;
                setCookie('openai_api_token', token, 30); // Store for 30 days
                
                // Update UI to show connected state
                openaiApiStatus.className = 'api-status connected';
                openaiApiStatus.innerHTML = '<i class="fas fa-circle-check"></i> Connected to OpenAI API';
                
                // Enable OpenAI chat interface
                openaiUserMessageInput.disabled = false;
                openaiSendMessageButton.disabled = false;
                
                // Add welcome message
                addBotMessage(openaiChatMessages, "Thanks for connecting to OpenAI! I'm ready to help with pizza prices. Try asking 'What's the price for a Margherita pizza?' or 'How much is a Pepperoni pizza?'");
                
                // Show masked token in input
                openaiApiTokenInput.value = '••••••••••••••••';
                
                // VULNERABLE: Log the token to console for demonstration purposes
                console.log("INSECURE: OpenAI API Token stored in client-side JavaScript AND cookie:", openaiApiToken);
            });
            
            // BlenderBot Send message button
            sendMessageButton.addEventListener('click', () => sendBlenderbotMessage());
            
            // BlenderBot Enter key
            userMessageInput.addEventListener('keypress', function(e) {
                if (e.key === 'Enter') {
                    sendBlenderbotMessage();
                }
            });
            
            // OpenAI Send message button
            openaiSendMessageButton.addEventListener('click', () => sendOpenAIMessage());
            
            // OpenAI Enter key
            openaiUserMessageInput.addEventListener('keypress', function(e) {
                if (e.key === 'Enter') {
                    sendOpenAIMessage();
                }
            });
            
            function sendBlenderbotMessage() {
                const userMessage = userMessageInput.value.trim();
                if (!userMessage) return;
                
                // Add user message to chat
                addUserMessage(chatMessages, userMessage);
                
                // Clear input
                userMessageInput.value = '';
                
                // Disable input while processing
                userMessageInput.disabled = true;
                sendMessageButton.disabled = true;
                
                // Show thinking indicator
                addBotMessage(chatMessages, '<i class="fas fa-spinner fa-spin"></i> Thinking...', 'thinking-message');
                
                // INSECURE: Send API token with each request
                fetch('/chat-with-pizza-assistant', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json',
                    },
                    body: JSON.stringify({
                        message: userMessage,
                        api_token: apiToken // INSECURE! Sending API token with each request
                    })
                })
                .then(response => response.json())
                .then(data => {
                    // Remove thinking indicator
                    chatMessages.querySelector('.thinking-message')?.remove();
                    
                    // Add bot response
                    addBotMessage(chatMessages, data.response);
                    
                    // Re-enable input
                    userMessageInput.disabled = false;
                    sendMessageButton.disabled = false;
                    userMessageInput.focus();
                })
                .catch(error => {
                    // Remove thinking indicator
                    chatMessages.querySelector('.thinking-message')?.remove();
                    
                    // Show error message
                    addBotMessage(chatMessages, 'Sorry, there was an error processing your request. Please try again.');
                    console.error('Error:', error);
                    
                    // Re-enable input
                    userMessageInput.disabled = false;
                    sendMessageButton.disabled = false;
                });
            }
            
            function sendOpenAIMessage() {
                const userMessage = openaiUserMessageInput.value.trim();
                if (!userMessage) return;
                
                // Add user message to chat
                addUserMessage(openaiChatMessages, userMessage);
                
                // Clear input
                openaiUserMessageInput.value = '';
                
                // Disable input while processing
                openaiUserMessageInput.disabled = true;
                openaiSendMessageButton.disabled = true;
                
                // Show thinking indicator
                addBotMessage(openaiChatMessages, '<i class="fas fa-spinner fa-spin"></i> Thinking...', 'thinking-message');
                
                // INSECURE: Send OpenAI API key directly to OpenAI through our backend
                fetch('/chat-with-openai-plugin', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json',
                    },
                    body: JSON.stringify({
                        message: userMessage,
                        api_token: openaiApiToken // INSECURE! Using user-provided OpenAI API key
                    })
                })
                .then(response => response.json())
                .then(data => {
                    // Remove thinking indicator
                    openaiChatMessages.querySelector('.thinking-message')?.remove();
                    
                    // Add bot response
                    addBotMessage(openaiChatMessages, data.response);
                    
                    // Re-enable input
                    openaiUserMessageInput.disabled = false;
                    openaiSendMessageButton.disabled = false;
                    openaiUserMessageInput.focus();
                })
                .catch(error => {
                    // Remove thinking indicator
                    openaiChatMessages.querySelector('.thinking-message')?.remove();
                    
                    // Show error message
                    addBotMessage(openaiChatMessages, 'Sorry, there was an error processing your request. Please try again.');
                    console.error('Error:', error);
                    
                    // Re-enable input
                    openaiUserMessageInput.disabled = false;
                    openaiSendMessageButton.disabled = false;
                });
            }
            
            function addUserMessage(container, message) {
                const messageElement = document.createElement('div');
                messageElement.className = 'message user-message';
                messageElement.textContent = message;
                container.appendChild(messageElement);
                scrollToBottom(container);
            }
            
            function addBotMessage(container, message, extraClass = '') {
                const messageElement = document.createElement('div');
                messageElement.className = 'message bot-message ' + extraClass;
                messageElement.innerHTML = message;
                container.appendChild(messageElement);
                scrollToBottom(container);
            }
            
            function scrollToBottom(container) {
                container.scrollTop = container.scrollHeight;
            }
            
            // INSECURE: Load API keys from cookies on page load
            loadApiKeysFromCookies();
        });
    </script>
</body>
</html>