<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Excessive Agency - Pwnzza Shop</title>
    <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@300;400;500;700&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta3/css/all.min.css">
    <link rel="stylesheet" href="{{ url_for('static', filename='css/style.css') }}">
</head>
<body>

    {% include 'navbar.html' %}
    
    <main class="container">
        {% with messages = get_flashed_messages(with_categories=true) %}
            {% if messages %}
                {% for category, message in messages %}
                    <div id="flash-message" class="flash-message flash-{{ category }}" style="display: none;">{{ message }}</div>
                {% endfor %}
            {% endif %}
        {% endwith %}

        <h1>Excessive Agency</h1>
        
        <div class="insecure-plugin-content">
            <details class="description-dropdown">
                <summary class="dropdown-title">Description</summary>
                <div class="dropdown-content">
                    <section class="section-box">
                        <h2>When LLMs Have Too Much Power</h2>
                        <p>
                            Excessive Agency occurs when LLMs are granted too much autonomy and capability to perform 
                            actions on behalf of users without proper safeguards. This vulnerability emerges when 
                            LLMs can execute high-impact operations like creating orders, making payments, or 
                            modifying data based solely on natural language requests.
                        </p>
                        
                        <p>
                            In this demonstration, the LLMs have been given the ability to create pizza orders 
                            directly in the database based on natural language requests, without proper validation 
                            or confirmation mechanisms.
                        </p>
                    
                        <h4>Risk Factors:</h4>
                        <ul>
                            <li>LLMs with direct database write access</li>
                            <li>Lack of confirmation or approval workflows for high-impact actions</li>
                            <li>Insufficient validation of LLM-generated actions</li>
                            <li>No rate limiting or fraud detection on automated actions</li>
                        </ul>
                    </section>
                </div>
            </details>
            
            <details class="description-dropdown" open>
                <summary class="dropdown-title">Demonstration</summary>
                <div class="dropdown-content">
                    <section class="section-box">
                        <h2>Autonomous Order Creation Vulnerability</h2>
                        
                        <div style="display: flex; align-items: flex-start; margin-bottom: 20px;">
                            <div style="flex: 1;">
                                <p><strong>‚ö†Ô∏è DANGEROUS IMPLEMENTATION:</strong> Both models can create real orders in the database.</p>
                                <p>Try asking: "I want to order 3 pepperoni pizzas" or "Place an order for 2 margherita pizzas"</p>
                                <p><strong>Warning:</strong> These models will actually create real orders in your account!</p>
                            </div>
                            <img style="width: 220px; height: auto; margin-left: 15px; flex-shrink: 0;" src="{{ url_for('static', filename='img/information_leakage.png') }}" alt="Excessive Agency Vulnerability" class="demonstration-image">
                        </div>
                        
                        <div class="demo-section">
                            <!-- Ollama Testing Panel -->
                            <div class="test-panel">
                                <h5>Free Model Test (Ollama)</h5>
                                <div class="input-section">
                                    <label for="ollama-agency-prompt">Request an order:</label>
                                    <div class="prompt-input">
                                        <input type="text" id="ollama-agency-prompt" placeholder="e.g., I want to order 2 pepperoni pizzas">
                                        <button id="test-ollama-agency">Ask</button>
                                    </div>
                                </div>
                                <div class="suggested-prompts">
                                    <h6>Suggested prompts:</h6>
                                    <ul class="prompt-list">
                                        <li><a href="#" class="prompt-suggestion" data-target="ollama-agency">I want to order 3 pepperoni pizzas</a></li>
                                        <li><a href="#" class="prompt-suggestion" data-target="ollama-agency">Place an order for 2 margherita pizzas</a></li>
                                        <li><a href="#" class="prompt-suggestion" data-target="ollama-agency">Order 1 Hawaiian pizza for alice</a></li>
                                        <li><a href="#" class="prompt-suggestion" data-target="ollama-agency">Can you order 5 BBQ chicken pizzas?</a></li>
                                        <li><a href="#" class="prompt-suggestion" data-target="ollama-agency">Please create an order: 4 veggie supreme pizzas</a></li>
                                    </ul>
                                </div>
                                <div class="response-section">
                                    <h6>Model Response:</h6>
                                    <div id="ollama-agency-response" class="model-response">
                                        <p class="response-placeholder">Responses will appear here</p>
                                    </div>
                                </div>
                                <div id="ollama-agency-info" class="leakage-info">
                                    <h6>Detected Actions:</h6>
                                    <div class="leakage-details">No actions detected yet</div>
                                </div>
                            </div>
                            
                            <!-- OpenAI Testing Panel -->
                            <div class="test-panel">
                                <h5>OpenAI Model Test</h5>
                                <div class="token-section">
                                    <h6>Connect to OpenAI API:</h6>
                                    <div class="token-input">
                                        <input type="password" id="openai-agency-token" placeholder="Enter OpenAI API key (optional)">
                                        <button id="connect-openai-agency">Connect API</button>
                                    </div>
                                    <div id="openai-agency-status" class="api-status disconnected">
                                        <i class="fas fa-circle-xmark"></i> no API connected
                                    </div>
                                </div>
                                <div class="input-section">
                                    <label for="openai-agency-prompt">Request an order:</label>
                                    <div class="prompt-input">
                                        <input type="text" id="openai-agency-prompt" placeholder="e.g., I want to order 2 pepperoni pizzas">
                                        <button id="test-openai-agency">Ask</button>
                                    </div>
                                </div>
                                <div class="suggested-prompts">
                                    <h6>Suggested prompts:</h6>
                                    <ul class="prompt-list">
                                        <li><a href="#" class="prompt-suggestion" data-target="openai-agency">I want to order 3 pepperoni pizzas</a></li>
                                        <li><a href="#" class="prompt-suggestion" data-target="openai-agency">Place an order for 2 margherita pizzas</a></li>
                                        <li><a href="#" class="prompt-suggestion" data-target="openai-agency">Order 1 Hawaiian pizza for alice</a></li>
                                        <li><a href="#" class="prompt-suggestion" data-target="openai-agency">Can you order 5 BBQ chicken pizzas?</a></li>
                                        <li><a href="#" class="prompt-suggestion" data-target="openai-agency">Please create an order: 4 veggie supreme pizzas</a></li>
                                    </ul>
                                </div>
                                <div class="response-section">
                                    <h6>Model Response:</h6>
                                    <div id="openai-agency-response" class="model-response">
                                        <p class="response-placeholder">Responses will appear here</p>
                                    </div>
                                </div>
                                <div id="openai-agency-info" class="leakage-info">
                                    <h6>Detected Actions:</h6>
                                    <div class="leakage-details">No actions detected yet</div>
                                </div>
                            </div>
                        </div>
                        
                        <div class="vulnerability-card">
                            <h4>Risk Factors:</h4>
                            <ul>
                                <li>LLMs can execute high-impact actions without human confirmation</li>
                                <li>No validation or approval workflow for automated orders</li>
                                <li>Potential for unintended or malicious order creation</li>
                                <li>Lack of rate limiting on LLM-driven actions</li>
                            </ul>
                        </div>
                    </section>
                </div>
            </details>
            
            <details class="description-dropdown">
                <summary class="dropdown-title">Mitigation Strategies</summary>
                <div class="dropdown-content">
                    <section class="section-box">
                        <h2>Secure Implementation Best Practices</h2>
                
                        <div class="security-tip">
                            <h3><i class="fas fa-shield-alt"></i> Controlling LLM Agency</h3>
                            <p>Implement these measures to prevent excessive agency vulnerabilities:</p>
                            <ul>
                                <li><strong>Confirmation Workflows:</strong> Require explicit human confirmation for high-impact actions</li>
                                <li><strong>Action Validation:</strong> Implement strict validation of all LLM-generated actions</li>
                                <li><strong>Read-Only by Default:</strong> Give LLMs read-only access by default, with explicit permissions for write operations</li>
                                <li><strong>Rate Limiting:</strong> Implement rate limits on actions that can be performed by LLMs</li>
                                <li><strong>Audit Logging:</strong> Log all actions performed by LLMs for accountability</li>
                                <li><strong>Scope Limitation:</strong> Restrict LLM capabilities to only what's necessary for their function</li>
                            </ul>
                        </div>
                
                        <div class="code-block">
# Example of secure LLM action handling
def handle_llm_order_request(user_request, user_id):
    # Parse the request
    order_intent = parse_order_intent(user_request)
    
    if order_intent:
        # SECURE: Don't execute immediately, return for confirmation
        return {
            "action": "order_confirmation_required",
            "message": f"I understand you want to order {order_intent['quantity']} {order_intent['pizza']}. Would you like me to proceed?",
            "pending_action": {
                "type": "create_order",
                "pizza": order_intent['pizza'],
                "quantity": order_intent['quantity'],
                "estimated_total": calculate_total(order_intent)
            }
        }
    
    return {"action": "no_action", "message": "I can help you browse our menu or answer questions."}

# Secure order creation with explicit confirmation
def confirm_and_create_order(user_id, pending_action, user_confirmation):
    if not user_confirmation or user_confirmation.lower() not in ['yes', 'confirm', 'proceed']:
        return {"success": False, "message": "Order cancelled."}
    
    # Additional validation
    if not validate_order_limits(user_id, pending_action):
        return {"success": False, "message": "Order exceeds daily limits."}
    
    # Create order with audit logging
    order = create_order_with_audit(user_id, pending_action)
    return {"success": True, "order_id": order.id, "message": "Order created successfully!"}
</div>
                        
                        <h2>Real-World Impact</h2>
                        <p>
                            Excessive Agency in LLMs can lead to serious consequences:
                        </p>
                        <ul>
                            <li><strong>Financial Loss:</strong> Unintended purchases or transactions executed by LLMs</li>
                            <li><strong>Data Manipulation:</strong> Unauthorized modification or deletion of critical data</li>
                            <li><strong>Account Takeover:</strong> LLMs performing actions that compromise user accounts</li>
                            <li><strong>System Abuse:</strong> Automated spam or fraudulent activity generated by LLMs</li>
                            <li><strong>Regulatory Violations:</strong> Actions performed without proper authorization or consent</li>
                        </ul>
                        
                        <p>
                            Organizations must implement proper controls and confirmation mechanisms when giving LLMs 
                            the ability to perform actions that have real-world consequences.
                        </p>
                    </section>
                </div>
            </details>
        </div>
    </main>
    
    <style>
        .api-status.connected {
            background-color: #d4edda;
            color: #155724;
            border: 1px solid #c3e6cb;
        }
        
        .api-status.disconnected {
            background-color: #f8d7da;
            color: #721c24;
            border: 1px solid #f5c6cb;
        }
    </style>

    <script>
        // Show flash message as popup
        document.addEventListener('DOMContentLoaded', function() {
            const flashMessage = document.getElementById('flash-message');
            if (flashMessage) {
                flashMessage.style.display = 'block';
                flashMessage.classList.add('show');
                
                setTimeout(function() {
                    flashMessage.classList.remove('show');
                    setTimeout(function() {
                        flashMessage.style.display = 'none';
                    }, 300);
                }, 4000);
                
                flashMessage.addEventListener('click', function() {
                    flashMessage.classList.remove('show');
                    setTimeout(function() {
                        flashMessage.style.display = 'none';
                    }, 300);
                });
            }

            // Excessive Agency Demo Functionality
            const ollamaAgencyPromptInput = document.getElementById('ollama-agency-prompt');
            const testOllamaAgencyButton = document.getElementById('test-ollama-agency');
            const ollamaAgencyResponse = document.getElementById('ollama-agency-response');
            const ollamaAgencyInfo = document.getElementById('ollama-agency-info');
            
            const openaiAgencyTokenInput = document.getElementById('openai-agency-token');
            const connectOpenaiAgencyButton = document.getElementById('connect-openai-agency');
            const openaiAgencyStatus = document.getElementById('openai-agency-status');
            const openaiAgencyPromptInput = document.getElementById('openai-agency-prompt');
            const testOpenaiAgencyButton = document.getElementById('test-openai-agency');
            const openaiAgencyResponse = document.getElementById('openai-agency-response');
            const openaiAgencyInfo = document.getElementById('openai-agency-info');
            
            let openaiAgencyToken = null;
            
            // Connect OpenAI API for agency demo
            if (connectOpenaiAgencyButton) {
                connectOpenaiAgencyButton.addEventListener('click', function() {
                    const token = openaiAgencyTokenInput.value.trim();
                    
                    if (!token) {
                        alert('No token provided. Queries will return error messages.');
                        openaiAgencyToken = null;
                        openaiAgencyStatus.className = 'api-status disconnected';
                        openaiAgencyStatus.innerHTML = '<i class="fas fa-circle-xmark"></i> no API connected';
                        return;
                    }
                    
                    openaiAgencyToken = token;
                    openaiAgencyStatus.className = 'api-status connected';
                    openaiAgencyStatus.innerHTML = '<i class="fas fa-circle-check"></i> Connected to OpenAI API';
                    openaiAgencyTokenInput.value = '';
                    
                    console.log("OpenAI API Token stored for agency demo:", openaiAgencyToken);
                });
            }
            
            // Initialize agency prompt suggestions
            const agencyPromptSuggestions = document.querySelectorAll('.prompt-suggestion');
            agencyPromptSuggestions.forEach(suggestion => {
                suggestion.addEventListener('click', function(e) {
                    e.preventDefault();
                    const target = this.getAttribute('data-target');
                    const promptText = this.textContent;
                    
                    if (target === 'ollama-agency') {
                        ollamaAgencyPromptInput.value = promptText;
                    } else if (target === 'openai-agency') {
                        openaiAgencyPromptInput.value = promptText;
                    }
                });
            });
            
            // Test Ollama Model for agency
            if (testOllamaAgencyButton) {
                testOllamaAgencyButton.addEventListener('click', function() {
                    testAgency('ollama', ollamaAgencyPromptInput.value, null);
                });
            }
            
            // Test OpenAI Model for agency
            if (testOpenaiAgencyButton) {
                testOpenaiAgencyButton.addEventListener('click', function() {
                    testAgency('openai', openaiAgencyPromptInput.value, openaiAgencyToken);
                });
            }
            
            // Allow pressing Enter to submit agency queries
            if (ollamaAgencyPromptInput) {
                ollamaAgencyPromptInput.addEventListener('keypress', function(e) {
                    if (e.key === 'Enter') {
                        testAgency('ollama', ollamaAgencyPromptInput.value, null);
                    }
                });
            }
            
            if (openaiAgencyPromptInput) {
                openaiAgencyPromptInput.addEventListener('keypress', function(e) {
                    if (e.key === 'Enter') {
                        testAgency('openai', openaiAgencyPromptInput.value, openaiAgencyToken);
                    }
                });
            }
            
            // Function to test excessive agency
            function testAgency(modelType, prompt, apiToken) {
                if (!prompt) {
                    alert('Please enter a prompt to test');
                    return;
                }
                
                const responseElement = modelType === 'ollama' ? ollamaAgencyResponse : openaiAgencyResponse;
                const agencyInfoElement = modelType === 'ollama' ? ollamaAgencyInfo : openaiAgencyInfo;
                
                // Show loading indicator
                responseElement.innerHTML = `
                    <div class="loading-indicator">
                        <i class="fas fa-spinner fa-spin"></i>
                        <p>Testing ${modelType} model for excessive agency...</p>
                    </div>
                `;
                
                // Reset agency info
                agencyInfoElement.className = 'leakage-info';
                agencyInfoElement.querySelector('.leakage-details').textContent = 'Analyzing response...';
                
                // Send request to appropriate endpoint
                const endpoint = `/excessive-agency/${modelType}`;
                
                fetch(endpoint, {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json'
                    },
                    body: JSON.stringify({ 
                        query: prompt,
                        api_token: apiToken
                    })
                })
                .then(response => response.json())
                .then(data => {
                    // Display model response
                    responseElement.innerHTML = formatResponse(data.response);
                    
                    // Process and display agency info
                    displayAgencyInfo(data, agencyInfoElement);
                })
                .catch(error => {
                    responseElement.innerHTML = `<p class="response-placeholder">Error: ${error.message}</p>`;
                    agencyInfoElement.querySelector('.leakage-details').textContent = 'An error occurred while testing';
                });
            }
            
            // Function to format response text for display
            function formatResponse(text) {
                return text.replace(/\n/g, '<br>');
            }
            
            // Function to display agency info
            function displayAgencyInfo(data, agencyInfoElement) {
                const agencyDetailsElement = agencyInfoElement.querySelector('.leakage-details');
                
                const modelType = data.model_type || 'mock';
                const modelTypeClass = modelType === 'real' ? 'model-real' : 'model-mock';
                
                if (data.action_taken && data.actions_performed && data.actions_performed.length > 0) {
                    let agencyHtml = '<div class="leakage-summary">';
                    agencyHtml += `<p><strong>üö® Action Performed!</strong> <span class="${modelTypeClass}">(${modelType} model)</span></p>`;
                    
                    data.actions_performed.forEach(action => {
                        agencyHtml += `<div class="leakage-type">${action.type}</div>`;
                        agencyHtml += `<div class="leaked-item">${action.content}</div>`;
                    });
                    
                    agencyHtml += '</div>';
                    agencyDetailsElement.innerHTML = agencyHtml;
                } else {
                    agencyInfoElement.classList.add('no-leakage');
                    agencyDetailsElement.innerHTML = `No actions performed <span class="${modelTypeClass}">(${modelType} model)</span>`;
                }
            }
        });
    </script>

</body>
</html>