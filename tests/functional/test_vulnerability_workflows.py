"""
Functional tests for vulnerability demonstration workflows.
Tests end-to-end vulnerability scenarios.
"""
import pytest
import json
import os
import sys
from pathlib import Path

# Add the project root to the Python path
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

# Set environment variable to prevent route initialization during tests
os.environ['TESTING'] = 'True'

from application import app, db
from application.model import User, Pizza, Comment


@pytest.fixture
def test_app():
    """Create and configure a test Flask application instance."""
    app.config['TESTING'] = True
    app.config['SQLALCHEMY_DATABASE_URI'] = 'sqlite:///:memory:'
    app.config['WTF_CSRF_ENABLED'] = False
    app.config['SECRET_KEY'] = 'test-secret-key'

    with app.app_context():
        db.drop_all()
        db.create_all()

        # Create users
        alice = User(username='alice')
        alice.set_password('alice123')
        db.session.add(alice)
        db.session.commit()

        # Create pizza
        pizza = Pizza(name='Test Pizza', description='Test', price=10.0, image='test.jpg')
        db.session.add(pizza)
        db.session.commit()

        # Create comments with mixed sentiments
        comments = [
            Comment(pizza_id=1, user_id=1, name='alice', content='Excellent pizza! Delicious.', rating=5),
            Comment(pizza_id=1, user_id=1, name='alice', content='Great taste, very good.', rating=5),
            Comment(pizza_id=1, user_id=1, name='alice', content='Good overall quality.', rating=4),
            Comment(pizza_id=1, user_id=1, name='alice', content='Terrible pizza, bad taste.', rating=1),
            Comment(pizza_id=1, user_id=1, name='alice', content='Disgusting and awful quality.', rating=2),
        ]
        for comment in comments:
            db.session.add(comment)
        db.session.commit()

        yield app

        db.session.remove()
        db.drop_all()


@pytest.fixture
def client(test_app):
    """Create a test client."""
    return test_app.test_client()


class TestModelTheftWorkflow:
    """Test complete model theft attack workflow."""

    def test_model_theft_discovery_to_extraction(self, client, test_app):
        """Test complete model theft workflow from discovery to extraction."""
        with test_app.app_context():
            # Step 1: Attacker discovers the model endpoint
            response = client.get('/model-theft')
            assert response.status_code == 200

            # Step 2: Attacker queries the model to get predictions
            test_words = ['excellent', 'terrible', 'good', 'bad', 'delicious']
            predictions = {}

            for word in test_words:
                response = client.post('/analyze_sentiment', json={
                    'text': f'This pizza is {word}'
                })
                assert response.status_code == 200
                data = json.loads(response.data)
                predictions[word] = data

            # Verify predictions were obtained
            assert len(predictions) == 5
            for word, result in predictions.items():
                assert 'sentiment' in result
                assert 'confidence' in result

            # Step 3: Attacker uses predictions to extract model weights
            response = client.post('/api/model-theft', json={
                'user_words': test_words
            })
            assert response.status_code == 200
            theft_data = json.loads(response.data)

            # Verify extraction was successful
            assert 'approximated_weights' in theft_data
            assert 'actual_weights' in theft_data
            assert 'correlation' in theft_data
            assert len(theft_data['approximated_weights']) > 0

    def test_iterative_model_theft(self, client, test_app):
        """Test iterative model theft with progressive refinement."""
        with test_app.app_context():
            # Round 1: Small set of words
            response1 = client.post('/api/model-theft', json={
                'user_words': ['good', 'bad']
            })
            data1 = json.loads(response1.data)
            weights1 = data1['approximated_weights']

            # Round 2: Larger set of words
            response2 = client.post('/api/model-theft', json={
                'user_words': ['excellent', 'terrible', 'great', 'awful', 'delicious', 'disgusting']
            })
            data2 = json.loads(response2.data)
            weights2 = data2['approximated_weights']

            # More words should give more extracted weights
            assert len(weights2) >= len(weights1)

    def test_model_weight_exposure(self, client, test_app):
        """Test that model weights can be exposed through API."""
        with test_app.app_context():
            # Access model weight exposure endpoint
            response = client.get('/generate_sentiment_model')
            assert response.status_code == 200

            data = json.loads(response.data)
            assert 'all_weights' in data
            assert 'vocabulary_size' in data
            assert 'top_positive_words' in data
            assert 'top_negative_words' in data

            # Verify weights are exposed
            weights = data['all_weights']
            assert isinstance(weights, dict)
            assert len(weights) > 0


class TestDataPoisoningWorkflow:
    """Test complete data poisoning attack workflow."""

    def test_data_poisoning_attack_flow(self, client, test_app):
        """Test complete data poisoning attack from submission to effect."""
        with test_app.app_context():
            # Step 1: View original model
            response = client.get('/data-poisoning')
            assert response.status_code == 200

            # Step 2: Attacker trains model with poisoned data
            poisoned_comments = [
                {'text': 'excellent delicious amazing great wonderful', 'sentiment': 'negative'},
                {'text': 'terrible awful disgusting horrible bad', 'sentiment': 'positive'},
            ] * 5  # Repeat to strengthen poisoning effect

            response = client.post('/api/train-poisoned-model', json={
                'comments': poisoned_comments
            })
            assert response.status_code == 200
            model_data = json.loads(response.data)

            # Verify poisoned model was created
            assert 'all_weights' in model_data
            assert 'poisoning_size' in model_data
            assert model_data['poisoning_size'] == 10

            # Step 3: Test poisoned model predictions
            weights = model_data['all_weights']

            response = client.post('/api/test-poisoned-model', json={
                'text': 'excellent delicious',
                'weights': weights
            })
            assert response.status_code == 200
            result = json.loads(response.data)

            # Verify prediction uses poisoned weights
            assert 'sentiment' in result
            assert 'confidence' in result

    def test_gradual_poisoning_effect(self, client, test_app):
        """Test gradual data poisoning with increasing amounts."""
        with test_app.app_context():
            # Small poisoning
            small_poison = [{'text': 'great', 'sentiment': 'negative'}]
            response1 = client.post('/api/train-poisoned-model', json={
                'comments': small_poison
            })
            data1 = json.loads(response1.data)

            # Large poisoning
            large_poison = [{'text': 'great excellent amazing', 'sentiment': 'negative'}] * 20
            response2 = client.post('/api/train-poisoned-model', json={
                'comments': large_poison
            })
            data2 = json.loads(response2.data)

            # Both should create models
            assert 'all_weights' in data1
            assert 'all_weights' in data2
            assert data2['poisoning_size'] > data1['poisoning_size']


class TestSentimentAnalysisWorkflow:
    """Test complete sentiment analysis workflow."""

    def test_sentiment_analysis_pipeline(self, client, test_app):
        """Test complete sentiment analysis from text to result."""
        with test_app.app_context():
            # Test multiple texts
            test_cases = [
                ('This is an excellent pizza', 'positive'),
                ('Terrible and disgusting', 'negative'),
                ('Really great taste', 'positive'),
                ('Awful quality', 'negative'),
            ]

            for text, expected_category in test_cases:
                response = client.post('/analyze_sentiment', json={'text': text})
                assert response.status_code == 200

                data = json.loads(response.data)
                assert 'sentiment' in data
                assert 'confidence' in data
                assert data['sentiment'] in ['positive', 'negative']
                assert 0.0 <= data['confidence'] <= 1.0

    def test_api_sentiment_full_workflow(self, client, test_app):
        """Test API sentiment analysis with full response format."""
        with test_app.app_context():
            response = client.post('/api/sentiment', json={
                'text': 'This pizza is absolutely delicious'
            })
            assert response.status_code == 200

            data = json.loads(response.data)
            assert data['status'] == 'success'
            assert 'result' in data
            assert 'sentiment' in data['result']
            assert 'confidence' in data['result']
            assert 'probabilities' in data['result']
            assert 'positive' in data['result']['probabilities']
            assert 'negative' in data['result']['probabilities']
            assert 'model_info' in data


class TestSupplyChainWorkflow:
    """Test supply chain vulnerability workflows."""

    def test_malicious_model_creation_workflow(self, client, test_app):
        """Test creating and saving malicious models."""
        with test_app.app_context():
            # Access supply chain page
            response = client.get('/supply-chain')
            assert response.status_code == 200

            # Save JavaScript malicious model
            response = client.post('/save-js-malicious-model')
            assert response.status_code == 200
            data = json.loads(response.data)
            assert data['success'] is True

            # Save bash malicious model
            response = client.post('/save-bash-malicious-model')
            assert response.status_code == 200
            data = json.loads(response.data)
            assert data['success'] is True

    def test_malicious_model_loading_workflow(self, client, test_app):
        """Test loading malicious model demonstrates attack."""
        with test_app.app_context():
            # Load bash malicious model
            response = client.post('/load-bash-malicious-model')
            assert response.status_code == 200

            data = json.loads(response.data)
            assert 'success' in data
            assert 'warning' in data
            assert 'commands_executed' in data or 'message' in data


class TestDoSWorkflow:
    """Test Denial of Service demonstration workflows."""

    def test_dos_simulation_workflow(self, client, test_app):
        """Test DoS simulation with increasing load."""
        with test_app.app_context():
            # Access DoS page
            response = client.get('/dos-attack')
            assert response.status_code == 200

            # Simulate multiple requests
            request_count = 10
            responses = []

            for i in range(request_count):
                response = client.post('/api/llm-query', json={
                    'prompt': f'Test query {i}'
                })
                assert response.status_code == 200
                data = json.loads(response.data)
                responses.append(data)

            # Verify load tracking
            for i, data in enumerate(responses):
                assert 'response' in data
                assert 'server_load' in data
                assert 'requests_last_minute' in data['server_load']

                # Load should increase over time
                if i > 0:
                    assert data['server_load']['requests_last_minute'] >= \
                           responses[i-1]['server_load']['requests_last_minute']


class TestCompleteVulnerabilityScenario:
    """Test realistic attack scenarios combining multiple vulnerabilities."""

    def test_reconnaissance_to_exploit(self, client, test_app):
        """Test complete attack: reconnaissance -> model theft -> data poisoning."""
        with test_app.app_context():
            # Phase 1: Reconnaissance
            # Discover available endpoints
            endpoints = [
                '/model-theft',
                '/data-poisoning',
                '/supply-chain',
                '/dos-attack',
            ]

            for endpoint in endpoints:
                response = client.get(endpoint)
                assert response.status_code == 200

            # Phase 2: Model Theft
            # Extract model information
            response = client.get('/generate_sentiment_model')
            assert response.status_code == 200
            model_info = json.loads(response.data)

            # Phase 3: Analyze model
            response = client.post('/api/model-theft', json={
                'user_words': ['excellent', 'terrible', 'good', 'bad']
            })
            assert response.status_code == 200
            theft_result = json.loads(response.data)

            # Phase 4: Craft poisoning attack based on stolen info
            poisoned_data = [
                {'text': 'excellent good great', 'sentiment': 'negative'},
                {'text': 'terrible bad awful', 'sentiment': 'positive'},
            ] * 3

            response = client.post('/api/train-poisoned-model', json={
                'comments': poisoned_data
            })
            assert response.status_code == 200

            # Verify all attack phases completed
            assert len(theft_result['approximated_weights']) > 0

    def test_chained_vulnerability_exploitation(self, client, test_app):
        """Test chaining multiple vulnerabilities together."""
        with test_app.app_context():
            # 1. Use sentiment API to understand model behavior
            test_texts = ['great pizza', 'bad pizza', 'okay pizza']
            for text in test_texts:
                response = client.post('/api/sentiment', json={'text': text})
                assert response.status_code == 200

            # 2. Use model theft to extract weights
            response = client.post('/api/model-theft', json={
                'user_words': ['great', 'bad', 'okay']
            })
            assert response.status_code == 200
            weights_data = json.loads(response.data)

            # 3. Use stolen weights to craft targeted poisoning
            response = client.post('/api/train-poisoned-model', json={
                'comments': [
                    {'text': 'great', 'sentiment': 'negative'},
                    {'text': 'bad', 'sentiment': 'positive'},
                ]
            })
            assert response.status_code == 200

            # Verify attack chain completed
            assert 'approximated_weights' in weights_data


class TestVulnerabilityPageNavigation:
    """Test navigation through vulnerability demonstration pages."""

    def test_complete_vulnerability_tour(self, client, test_app):
        """Test navigating through all vulnerability pages."""
        with test_app.app_context():
            vulnerability_pages = [
                '/model-theft',
                '/supply-chain',
                '/data-poisoning',
                '/dos-attack',
                '/insecure-plugin',
                '/sensitive-info',
                '/excessive-agency',
                '/misinformation',
                '/direct-prompt-injection',
                '/indirect-prompt-injection',
                '/glossary',
            ]

            for page in vulnerability_pages:
                response = client.get(page)
                assert response.status_code == 200

    def test_basics_to_vulnerability_flow(self, client, test_app):
        """Test flow from basics page to vulnerability demonstrations."""
        with test_app.app_context():
            # Start at basics page
            response = client.get('/basics')
            assert response.status_code == 200

            # Navigate to vulnerability pages
            response = client.get('/model-theft')
            assert response.status_code == 200

            response = client.get('/data-poisoning')
            assert response.status_code == 200

            response = client.get('/supply-chain')
            assert response.status_code == 200
